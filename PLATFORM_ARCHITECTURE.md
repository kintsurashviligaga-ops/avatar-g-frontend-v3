# üé¨ AVATAR G - COMPLETE CREATIVE PLATFORM
## Full Implementation Guide & Architecture

**Version:** 2.0.0  
**Status:** üöÄ Production Ready  
**Stack:** Next.js 14 + TypeScript + Supabase + AI Providers  

---

## üìñ TABLE OF CONTENTS

1. [Platform Overview](#platform-overview)
2. [Architecture](#architecture)
3. [Database Schema](#database-schema)
4. [File Structure](#file-structure)
5. [Implementation Roadmap](#implementation-roadmap)
6. [API Routes](#api-routes)
7. [UI Components](#ui-components)
8. [State Management](#state-management)
9. [Provider Integration](#provider-integration)
10. [Deployment](#deployment)
11. [Testing](#testing)

---

## üéØ PLATFORM OVERVIEW

Avatar G is a **unified creative platform** combining three integrated services:

### **Service 1: Avatar Builder** ‚úÖ COMPLETE
- 3D full-body avatar generation
- Wardrobe & accessories (drag & drop)
- Voice Lab (3 voice slots: A/B/C)
- Talking Avatar mode
- Live Creator Mode (WebRTC)
- Route: `/services/avatar-builder`

### **Service 2: Music & Song Studio** üéµ NEW
- Suno-like music generation
- Lyrics editor (auto/custom/instrumental)
- Style presets (genre, mood, era, tempo)
- Voice cloning for singing (duet/trio modes)
- Remix & extend tracks
- Cover art generation
- Route: `/services/music-studio`

### **Service 3: Video Generator** üé¨ NEW
- **Avatar Performance Mode:** Avatar sings/dances to music
- **Image Animation Mode:** Animate uploaded images to music
- **Mixed Mode:** Alternate avatar + images
- Lip-sync, lyrics overlay, transitions, filters
- FFmpeg server-side rendering
- Route: `/services/video-studio`

---

## üèóÔ∏è ARCHITECTURE

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CLIENT (Next.js)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Avatar    ‚îÇ  ‚îÇ    Music     ‚îÇ  ‚îÇ     Video     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Builder   ‚îÇ  ‚îÇ    Studio    ‚îÇ  ‚îÇ    Studio     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                    ‚îÇ           ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                          ‚îÇ                                ‚îÇ
‚îÇ                    Zustand Stores                         ‚îÇ
‚îÇ                          ‚îÇ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              API ROUTES (Server-Side Only)               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ /api/avatar  ‚îÇ  ‚îÇ  /api/music  ‚îÇ  ‚îÇ  /api/video  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                          ‚îÇ                                ‚îÇ
‚îÇ                  Provider Factory                         ‚îÇ
‚îÇ                          ‚îÇ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                 ‚ñº                 ‚ñº
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  Stability   ‚îÇ  ‚îÇ  Replicate   ‚îÇ  ‚îÇ    FFmpeg    ‚îÇ
  ‚îÇ     AI       ‚îÇ  ‚îÇ    Music     ‚îÇ  ‚îÇ  Video Proc  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                 ‚îÇ                 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Supabase Backend     ‚îÇ
              ‚îÇ  ‚Ä¢ Database (Postgres) ‚îÇ
              ‚îÇ  ‚Ä¢ Storage (S3-like)   ‚îÇ
              ‚îÇ  ‚Ä¢ Auth                ‚îÇ
              ‚îÇ  ‚Ä¢ Job Queue           ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üóÑÔ∏è DATABASE SCHEMA

### **Tables Created**

| Table | Purpose | Key Features |
|-------|---------|--------------|
| `avatars` | Avatar storage | RLS, status tracking, turnaround URLs |
| `wardrobe_items` | Clothing/accessories | Categories, tags, user/stock items |
| `voice_profiles` | Voice cloning | 3 slots (A/B/C), consent required |
| `talk_clips` | Talking avatar outputs | Links to avatar + audio |
| `tracks` | Music/songs | Genre, mood, waveform data, versioning |
| `video_clips` | Generated videos | Scenes JSON, render logs, stats |
| `projects` | Organization | Groups avatars + tracks + videos |
| `media_assets` | Uploaded images | For video backgrounds/animations |
| `jobs` | Async task queue | Status, progress, error handling |
| `presets` | Saved configs | Avatar + music style presets |
| `live_sessions` | WebRTC tracking | Duration, character switches |

### **Storage Buckets**

- `avatars` (public) - Generated avatar images
- `wardrobe` (public) - Clothing images
- `voices` (private) - Voice samples
- `generated-audio` (public) - Music tracks
- `covers` (public) - Album artwork
- `talk-clips` (public) - Talking avatar audio/video
- `video-clips` (public) - Final rendered videos
- `media-assets` (private) - User-uploaded images

### **Migrations**

Run in order:
1. `001_avatar_builder_schema.sql` ‚úÖ Already created
2. `002_music_video_schema.sql` ‚úÖ Already created

---

## üìÅ FILE STRUCTURE

```
avatar-g-frontend-v3/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ avatar/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate/route.ts          ‚úÖ Created
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ talk/route.ts              ‚úÖ Created
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upload/route.ts            ‚úÖ Created
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train/route.ts             ‚úÖ Created
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ music/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate/route.ts          üìù See below
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ remix/route.ts             üìù See below
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extend/route.ts            üìù See below
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cover/route.ts             üìù See below
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate/route.ts          üìù See below
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preview/route.ts           üìù See below
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jobs/[id]/route.ts             ‚úÖ Created
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ avatar-builder/page.tsx        ‚úÖ Exists (localized)
‚îÇ       ‚îú‚îÄ‚îÄ music-studio/page.tsx          üìù See below
‚îÇ       ‚îî‚îÄ‚îÄ video-studio/page.tsx          üìù See below
‚îÇ
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ music/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TrackCard.tsx                  üìù Music track display
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WaveformPlayer.tsx             üìù Audio player with waveform
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LyricsEditor.tsx               üìù Lyrics input component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ StyleSelector.tsx              üìù Genre/mood chips
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VoiceSelector.tsx              üìù Voice slot picker
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ video/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SceneTimeline.tsx              üìù Visual scene editor
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VideoPreview.tsx               üìù Video player
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BackgroundSelector.tsx         üìù Background config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ LyricsStyleEditor.tsx          üìù Text styling
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ shared/
‚îÇ       ‚îú‚îÄ‚îÄ JobProgress.tsx                üìù Universal progress bar
‚îÇ       ‚îú‚îÄ‚îÄ AssetLibrary.tsx               üìù Unified library view
‚îÇ       ‚îî‚îÄ‚îÄ AnimatedBackground.tsx         üìù Premium backgrounds
‚îÇ
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interfaces.ts                  ‚úÖ Created (avatar)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ music-interfaces.ts            ‚úÖ Created
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stability.ts                   ‚úÖ Created (FIXED)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ replicate.ts                   ‚úÖ Created
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mock.ts                        ‚úÖ Created (avatar)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ music-mock.ts                  ‚úÖ Created
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factory.ts                     ‚úÖ Created (avatar only)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ platform-factory.ts            ‚úÖ Created (complete)
‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îú‚îÄ‚îÄ useMusicStudio.ts                  ‚úÖ Created
‚îÇ   ‚îú‚îÄ‚îÄ useVideoStudio.ts                  ‚úÖ Created
‚îÇ   ‚îî‚îÄ‚îÄ useLibrary.ts                      üìù See below
‚îÇ
‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îú‚îÄ‚îÄ avatar-builder.ts                  ‚úÖ Created
‚îÇ   ‚îî‚îÄ‚îÄ music-video.ts                     ‚úÖ Created
‚îÇ
‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îî‚îÄ‚îÄ migrations/
‚îÇ       ‚îú‚îÄ‚îÄ 001_avatar_builder_schema.sql  ‚úÖ Created
‚îÇ       ‚îî‚îÄ‚îÄ 002_music_video_schema.sql     ‚úÖ Created
‚îÇ
‚îî‚îÄ‚îÄ DOCS/
    ‚îú‚îÄ‚îÄ DEPLOYMENT_GUIDE.md                ‚úÖ Created
    ‚îú‚îÄ‚îÄ ARCHITECTURE.md                    ‚úÖ Created (this file)
    ‚îî‚îÄ‚îÄ IMPLEMENTATION_SUMMARY.md          ‚úÖ Created
```

---

## üöÄ IMPLEMENTATION ROADMAP

### **Phase 1: Foundation** ‚úÖ COMPLETE
- [x] Avatar Builder (full feature set)
- [x] Database schema (avatars, voices, wardrobe)
- [x] Provider adapter layer (Stability, Replicate, Mock)
- [x] Multi-language support (KA/EN/RU)
- [x] Job system infrastructure

### **Phase 2: Music Studio** üéµ IN PROGRESS
- [x] Database schema for tracks
- [x] TypeScript types for music
- [x] Music provider interfaces
- [x] Mock music provider
- [x] Zustand store for music state
- [ ] Music Studio UI components
- [ ] API routes for music generation
- [ ] Waveform visualization
- [ ] Audio player component

### **Phase 3: Video Studio** üé¨ IN PROGRESS
- [x] Database schema for video clips
- [x] TypeScript types for video
- [x] Video provider interfaces
- [x] Mock video provider
- [x] Zustand store for video state
- [ ] Video Studio UI components
- [ ] API routes for video generation
- [ ] FFmpeg integration (server-side)
- [ ] Scene timeline editor
- [ ] Video preview player

### **Phase 4: Integration** üîó NEXT
- [ ] Cross-service asset selection
- [ ] Unified library view
- [ ] Project management system
- [ ] Share & export functionality

### **Phase 5: Polish & Launch** ‚ú® FINAL
- [ ] Premium animations (Framer Motion)
- [ ] Animated backgrounds
- [ ] Loading states & skeletons
- [ ] Error handling UI
- [ ] Onboarding flow
- [ ] Analytics integration
- [ ] Performance optimization

---

## üîå API ROUTES

### **Music Generation**

#### `POST /api/music/generate`

```typescript
// Request
interface GenerateTrackRequest {
  prompt: string;
  lyrics?: string;
  lyrics_mode?: 'auto' | 'custom' | 'instrumental';
  genre?: string;
  mood?: string;
  language?: 'ka' | 'en' | 'ru' | 'instrumental';
  style_tags?: string[];
  use_custom_vocals?: boolean;
  voice_slots?: ('A' | 'B' | 'C')[];
}

// Response
interface GenerateTrackResponse {
  job_id: string;
  track_id: string;
  status: 'queued' | 'processing' | 'completed' | 'failed';
}

// Implementation
import { platformProviders } from '@/lib/providers/platform-factory';

export async function POST(request: Request) {
  // 1. Auth check
  // 2. Parse & validate request
  // 3. Create track record in DB
  // 4. Create job record
  // 5. Start generation async
  //    - musicProvider.generate()
  //    - If custom vocals: vocalProvider.addVocals()
  //    - coverArtProvider.generateCover()
  // 6. Upload to storage
  // 7. Update track record
  // 8. Return job_id
}
```

#### `POST /api/music/remix`

```typescript
interface RemixTrackRequest {
  track_id: string;
  new_prompt: string;
  keep_vocals?: boolean;
}

// Uses musicProvider.remix()
```

#### `POST /api/music/extend`

```typescript
interface ExtendTrackRequest {
  track_id: string;
  extend_from_timestamp: number;
  target_duration: number;
}

// Uses musicProvider.extend()
```

### **Video Generation**

#### `POST /api/video/generate`

```typescript
interface GenerateVideoRequest {
  track_id?: string;
  avatar_id?: string;
  video_mode: 'avatar_performance' | 'image_animation' | 'mixed';
  scenes?: VideoScene[];
  avatar_action?: 'singing' | 'dancing' | 'talking';
  enable_lip_sync?: boolean;
  background_config?: BackgroundConfig;
  show_lyrics?: boolean;
  resolution?: '720p' | '1080p' | '4K';
}

// Implementation
export async function POST(request: Request) {
  // 1. Auth check
  // 2. Validate assets exist
  // 3. Create video_clip record
  // 4. Create job
  // 5. Start rendering (async)
  //    - videoProvider.generateVideo()
  //    - FFmpeg pipeline (server-side)
  // 6. Upload to storage
  // 7. Update video_clip record
  // 8. Return job_id
}
```

---

## üé® UI COMPONENTS (Code Snippets)

###** WaveformPlayer Component**

```tsx
// components/music/WaveformPlayer.tsx
'use client';

import { useEffect, useRef, useState } from 'react';
import { motion } from 'framer-motion';
import { Play, Pause, Volume2 } from 'lucide-react';

interface WaveformPlayerProps {
  audioUrl: string;
  waveformData?: number[];
  onTimeUpdate?: (time: number) => void;
}

export function WaveformPlayer({
  audioUrl,
  waveformData,
  onTimeUpdate
}: WaveformPlayerProps) {
  const audioRef = useRef<HTMLAudioElement>(null);
  const [playing, setPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  
  const togglePlay = () => {
    if (audioRef.current) {
      if (playing) {
        audioRef.current.pause();
      } else {
        audioRef.current.play();
      }
      setPlaying(!playing);
    }
  };
  
  return (
    <div className="flex items-center gap-4 p-4 bg-black/20 backdrop-blur-md rounded-xl border border-white/10">
      <button
        onClick={togglePlay}
        className="w-12 h-12 flex items-center justify-center rounded-full bg-gradient-to-r from-purple-500 to-pink-500 hover:scale-105 transition-transform"
      >
        {playing ? <Pause size={20} /> : <Play size={20} className="ml-1" />}
      </button>
      
      <div className="flex-1">
        <div className="flex items-center gap-1 h-16">
          {waveformData?.map((amplitude, i) => (
            <motion.div
              key={i}
              className="flex-1 bg-gradient-to-t from-purple-500 to-pink-500 rounded-full"
              style={{
                height: `${amplitude * 100}%`,
                opacity: (i / waveformData.length) < (currentTime / duration) ? 1 : 0.3
              }}
              animate={playing ? { scaleY: [1, 1.2, 1] } : {}}
              transition={{ duration: 0.5, repeat: Infinity, delay: i * 0.05 }}
            />
          ))}
        </div>
        
        <div className="flex justify-between text-xs text-white/60 mt-2">
          <span>{formatTime(currentTime)}</span>
          <span>{formatTime(duration)}</span>
        </div>
      </div>
      
      <audio
        ref={audioRef}
        src={audioUrl}
        onTimeUpdate={(e) => {
          const time = e.currentTarget.currentTime;
          setCurrentTime(time);
          onTimeUpdate?.(time);
        }}
        onLoadedMetadata={(e) => setDuration(e.currentTarget.duration)}
        onEnded={() => setPlaying(false)}
      />
    </div>
  );
}

function formatTime(seconds: number): string {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins}:${secs.toString().padStart(2, '0')}`;
}
```

### **Scene Timeline Editor**

```tsx
// components/video/SceneTimeline.tsx
'use client';

import { useVideoStudio } from '@/store/useVideoStudio';
import { motion, Reorder } from 'framer-motion';
import { Image, User, Trash2 } from 'lucide-react';

export function SceneTimeline() {
  const { scenes, reorderScenes, removeScene, updateScene } = useVideoStudio();
  
  return (
    <div className="p-6 bg-black/20 backdrop-blur-md rounded-xl border border-white/10">
      <h3 className="text-lg font-semibold mb-4">Scene Timeline</h3>
      
      <Reorder.Group
        axis="x"
        values={scenes}
        onReorder={(newOrder) => {
          // Update scene order
          newOrder.forEach((scene, index) => {
            const oldIndex = scenes.findIndex(s => s.id === scene.id);
            if (oldIndex !== index) {
              reorderScenes(oldIndex, index);
            }
          });
        }}
        className="flex gap-4 overflow-x-auto pb-4"
      >
        {scenes.map((scene, index) => (
          <Reorder.Item
            key={scene.id}
            value={scene}
            className="flex-shrink-0"
          >
            <motion.div
              className="w-40 h-32 bg-gradient-to-br from-purple-900/50 to-pink-900/50 rounded-lg border-2 border-white/10 hover:border-white/30 transition-colors cursor-move p-4"
              whileHover={{ scale: 1.05 }}
              whileTap={{ scale: 0.95 }}
            >
              <div className="flex items-center justify-between mb-2">
                {scene.type === 'avatar' ? (
                  <User size={20} className="text-purple-400" />
                ) : (
                  <Image size={20} className="text-pink-400" />
                )}
                
                <button
                  onClick={() => removeScene(scene.id)}
                  className="text-red-400 hover:text-red-300"
                >
                  <Trash2 size={16} />
                </button>
              </div>
              
              <div className="text-sm text-white/80">
                Scene {index + 1}
              </div>
              <div className="text-xs text-white/60">
                {scene.duration.toFixed(1)}s
              </div>
            </motion.div>
          </Reorder.Item>
        ))}
      </Reorder.Group>
      
      {scenes.length === 0 && (
        <div className="text-center text-white/40 py-8">
          No scenes yet. Add assets to generate scenes.
        </div>
      )}
    </div>
  );
}
```

---

## üé¨ VIDEO RENDERING (FFmpeg Integration)

### **Server-Side Video Pipeline**

```typescript
// lib/video/ffmpeg-renderer.ts
import ffmpeg from 'fluent-ffmpeg';
import { createWriteStream } from 'fs';
import { tmpdir } from 'os';
import path from 'path';

export interface RenderVideoOptions {
  audioUrl: string;
  scenes: Array<{
    type: 'avatar' | 'image';
    asset_url: string;
    start_time: number;
    duration: number;
  }>;
  resolution: '720p' | '1080p' | '4K';
  subtitles?: Array<{
    text: string;
    start_time: number;
    end_time: number;
  }>;
  onProgress?: (progress: number) => void;
}

export async function renderVideo(options: RenderVideoOptions): Promise<string> {
  const { audioUrl, scenes, resolution, subtitles, onProgress } = options;
  
  // 1. Download audio
  const audioPath = await downloadFile(audioUrl, 'audio.mp3');
  
  // 2. Create video from scenes
  const videoPath = await createVideoFromScenes(scenes, resolution);
  
  // 3. Add subtitles if provided
  let finalVideo = videoPath;
  if (subtitles && subtitles.length > 0) {
    finalVideo = await addSubtitles(videoPath, subtitles);
  }
  
  // 4. Combine audio + video
  const outputPath = path.join(tmpdir(), `output-${Date.now()}.mp4`);
  
  await new Promise((resolve, reject) => {
    ffmpeg()
      .input(finalVideo)
      .input(audioPath)
      .outputOptions([
        '-c:v libx264',
        '-c:a aac',
        '-shortest',
        '-pix_fmt yuv420p'
      ])
      .on('progress', (progress) => {
        onProgress?.(progress.percent || 0);
      })
      .on('end', resolve)
      .on('error', reject)
      .save(outputPath);
  });
  
  return outputPath;
}

async function createVideoFromScenes(
  scenes: RenderVideoOptions['scenes'],
  resolution: string
): Promise<string> {
  // Implementation:
  // 1. Download all scene assets
  // 2. Apply effects (zoom, pan, etc.)
  // 3. Concatenate scenes with transitions
  // 4. Return video path
}

async function addSubtitles(
  videoPath: string,
  subtitles: RenderVideoOptions['subtitles']
): Promise<string> {
  // Implementation:
  // 1. Generate SRT file from subtitles array
  // 2. Use FFmpeg to burn subtitles into video
  // 3. Return new video path
}
```

---

## üé≠ PREMIUM UI DESIGN SYSTEM

### **Animated Background**

```tsx
// components/shared/AnimatedBackground.tsx
'use client';

import { motion } from 'framer-motion';

export function AnimatedBackground() {
  return (
    <div className="fixed inset-0 -z-10 overflow-hidden">
      {/* Gradient orbs */}
      <motion.div
        className="absolute top-1/4 left-1/4 w-96 h-96 bg-purple-500/20 rounded-full filter blur-3xl"
        animate={{
          x: [0, 100, 0],
          y: [0, 50, 0],
          scale: [1, 1.2, 1]
        }}
        transition={{
          duration: 20,
          repeat: Infinity,
          ease: "linear"
        }}
      />
      
      <motion.div
        className="absolute bottom-1/4 right-1/4 w-96 h-96 bg-pink-500/20 rounded-full filter blur-3xl"
        animate={{
          x: [0, -100, 0],
          y: [0, -50, 0],
          scale: [1, 1.1, 1]
        }}
        transition={{
          duration: 15,
          repeat: Infinity,
          ease: "linear"
        }}
      />
      
      {/* Grid overlay */}
      <div 
        className="absolute inset-0"
        style={{
          backgroundImage: `linear-gradient(rgba(255,255,255,0.02) 1px, transparent 1px),
                           linear-gradient(90deg, rgba(255,255,255,0.02) 1px, transparent 1px)`,
          backgroundSize: '50px 50px'
        }}
      />
    </div>
  );
}
```

### **Glass Panel Component**

```tsx
// components/shared/GlassPanel.tsx
import { ReactNode } from 'react';
import { motion } from 'framer-motion';
import { cn } from '@/lib/utils';

interface GlassPanelProps {
  children: ReactNode;
  className?: string;
  hover?: boolean;
}

export function GlassPanel({ children, className, hover = true }: GlassPanelProps) {
  return (
    <motion.div
      className={cn(
        "bg-black/20 backdrop-blur-md border border-white/10 rounded-xl overflow-hidden",
        hover && "hover:border-white/20 hover:bg-black/30 transition-all duration-300",
        className
      )}
      whileHover={hover ? { scale: 1.02 } : undefined}
      transition={{ duration: 0.2 }}
    >
      {children}
    </motion.div>
  );
}
```

---

## üåê MULTI-LANGUAGE EXPANSION

The i18n system is already set up  for KA/EN/RU. To expand music & video UI:

**Add to `lib/i18n/LanguageContext.tsx`:**

```typescript
// Music Studio keys
"music.studio.title": {
  ka: "·Éõ·É£·É°·Éò·Éô·Éò·É° ·É°·É¢·É£·Éì·Éò·Éê",
  en: "Music Studio",
  ru: "–ú—É–∑—ã–∫–∞–ª—å–Ω–∞—è —Å—Ç—É–¥–∏—è"
},
"music.generate": {
  ka: "·Éõ·É£·É°·Éò·Éô·Éò·É° ·Éí·Éî·Éú·Éî·É†·Éò·É†·Éî·Éë·Éê",
  en: "Generate Music",
  ru: "–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º—É–∑—ã–∫—É"
},
"music.lyrics.auto": {
  ka: "·Éê·Éï·É¢·Éù·Éõ·Éê·É¢·É£·É†·Éò ·É¢·Éî·É•·É°·É¢·Éò",
  en: "Auto Lyrics",
  ru: "–ê–≤—Ç–æ-—Ç–µ–∫—Å—Ç"
},
"music.voice.duet": {
  ka: "·Éì·É£·Éî·É¢·Éò",
  en: "Duet",
  ru: "–î—É—ç—Ç"
},

// Video Studio keys
"video.studio.title": {
  ka: "·Éï·Éò·Éì·Éî·Éù ·É°·É¢·É£·Éì·Éò·Éê",
  en: "Video Studio",
  ru: "–í–∏–¥–µ–æ —Å—Ç—É–¥–∏—è"
},
"video.mode.avatar": {
  ka: "·Éê·Éï·Éê·É¢·Éê·É†·Éò·É° ·É®·Éî·É°·É†·É£·Éö·Éî·Éë·Éê",
  en: "Avatar Performance",
  ru: "–í—ã—Å—Ç—É–ø–ª–µ–Ω–∏–µ –∞–≤–∞—Ç–∞—Ä–∞"
},
"video.render.start": {
  ka: "·É†·Éî·Éú·Éì·Éî·É†·Éò·É° ·Éì·Éê·É¨·Éß·Éî·Éë·Éê",
  en: "Start Render",
  ru: "–ù–∞—á–∞—Ç—å —Ä–µ–Ω–¥–µ—Ä"
}
```

---

## ‚úÖ 10-MINUTE TESTING CHECKLIST

### **Quick Smoke Test**

```bash
# 1. Setup (2 min)
npm install
cp .env.example .env.local
# Add Supabase + Stability AI keys

# 2. Database (2 min)
# Run migrations in Supabase SQL Editor
# Create storage buckets

# 3. Run dev server (1 min)
npm run dev

# 4. Test Avatar Builder (2 min)
# - Visit /services/avatar-builder
# - Switch language (KA/EN/RU)
# - Generate avatar
# - Check gallery

# 5. Test Music Studio (2 min)
# - Visit /services/music-studio
# - Enter prompt
# - Generate track (mock mode)
# - Check waveform display

# 6. Test Video Studio (1 min)
# - Visit /services/video-studio
# - Select track + avatar
# - Preview configuration
# - Start render (mock mode)

# ‚úÖ If all pages load and mock providers work ‚Üí PASS
```

---

## üöÄ DEPLOYMENT TO VERCEL

### **Environment Variables**

```bash
# Supabase
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

# AI Providers
STABILITY_API_KEY=           # Avatar + cover art
REPLICATE_API_TOKEN=         # Alternative avatar + music models
OPENAI_API_KEY=              # Optional: face analysis
ELEVENLABS_API_KEY=          # Optional: voice cloning
RUNWAY_API_KEY=              # Optional: video generation

# App
NEXT_PUBLIC_APP_URL=https://your-domain.com
```

### **Build Command**

```bash
npm run build
```

### **Checklist**

- [ ] All env vars set in Vercel
- [ ] Database migrations run
- [ ] Storage buckets created
- [ ] Domain configured
- [ ] Deploy!

---

## üìä PERFORMANCE TARGETS

| Metric | Target | Measurement |
|--------|--------|-------------|
| Avatar generation | < 30s | Job completion time |
| Music generation | < 60s | Job completion time |
| Video rendering (1080p, 3min) | < 5min | Job completion time |
| Page load (FCP) | < 1.5s | Lighthouse |
| UI interactions | < 100ms | User testing |
| Storage per user | < 1GB | Supabase dashboard |

---

## üé¨ WHAT'S NEXT?

### **Immediate Priorities**

1. **Complete Music Studio UI** - TrackCard, WaveformPlayer, LyricsEditor
2. **Complete Video Studio UI** - SceneTimeline, VideoPreview
3. **API Routes** - Music & video generation endpoints
4. **FFmpeg Integration** - Server-side video rendering
5. **Premium Animations** - Framer Motion transitions everywhere

### **Future Enhancements**

- Real-time collaboration (multiple users, one project)
- Social features (share tracks, remix others)
- Marketplace (sell avatars, tracks, presets)
- Mobile app (React Native)
- Desktop app (Electron)

---

## üìû SUPPORT & RESOURCES

**Documentation:**
- [Deployment Guide](./DEPLOYMENT_GUIDE.md)
- [Implementation Summary](./IMPLEMENTATION_SUMMARY.md)
- This Architecture Guide

**External Resources:**
- [Next.js Docs](https://nextjs.org/docs)
- [Supabase Docs](https://supabase.com/docs)
- [FFmpeg Docs](https://ffmpeg.org/documentation.html)
- [Framer Motion](https://www.framer.com/motion/)

---

**Built with ‚ù§Ô∏è for creators**  
**Version 2.0.0 | February 2026**  
**Status: üöÄ Production Ready (Avatar Builder) + üèóÔ∏è In Progress (Music & Video)**

